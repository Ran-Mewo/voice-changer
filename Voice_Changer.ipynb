{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ran-Mewo/voice-changer/blob/main/Voice_Changer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[RVC on Colab](https://colab.research.google.com/github/w-okada/voice-changer/blob/master/Realtime_Voice_Changer_on_Colab.ipynb) but upto **11x faster!** <br>And it supports saving things over to Google Drive (Optional)<br><br>\n",
        "**limitations being it's most likely running an older version of [w-okada's Voice Changer](https://github.com/w-okada/voice-changer) but it can be updated if you pass in an updated image*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **⬇ VERY IMPORTANT ⬇**\n",
        "\n",
        "You can use the following settings for better results:\n",
        "\n",
        "If you're using a index: `f0: RMVPE_ONNX | Chunk: 112 or higher | Extra: 8192`<br>\n",
        "If you're not using a index: `f0: RMVPE_ONNX | Chunk: 96 or higher | Extra: 16384`<br>\n",
        "**Don't forget to select a T4 GPU in the GPU field, <b>NEVER</b> use CPU!\n",
        "> Seems that PTH models performance better than ONNX for now, you can still try ONNX models and see if it satisfies you\n",
        "\n",
        "\n",
        "*You can always [click here](https://github.com/YunaOneeChan/Voice-Changer-Settings) to check if these settings are up-to-date*\n",
        "\n",
        "---\n",
        "\n",
        "### <font color=red>⬇ Always use Colab GPU! (**IMPORTANT!**) ⬇</font>\n",
        "You need to use a Colab GPU so the Voice Changer can work faster and better\\\n",
        "Use the menu above and click on **Runtime** » **Change runtime** » **Hardware acceleration** to select a GPU (**T4 is the free one**)\n",
        "\n",
        "---\n",
        "**Credits**<br>\n",
        "Realtime Voice Changer by [w-okada](https://github.com/w-okada)<br>\n",
        "Notebook files updated by [rafacasari](https://github.com/Rafacasari)<br>\n",
        "Recommended settings by [YunaOneeChan](https://github.com/YunaOneeChan)<br>\n",
        "This specific notebook by [Ran](https://github.com/Ran-Mewo)\n",
        "\n",
        "**If it's an issue with RVC or the voice changer header over to** [AI Hub Discord](https://discord.gg/aihub) » ***#help-realtime-vc***\n",
        "\n",
        "**If it's an issue with this notebook specifically or you'd like to request an update to the voice changer then message me at discord** [yourcuteneko](<https://discord.com/users/721351466828300350>)"
      ],
      "metadata": {
        "id": "_TdRfgeR2CL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initialize docker by using [Docker in Colab](https://github.com/drengskapur/docker-in-colab) and setup the image<br>\n",
        "# @markdown We don't really use docker for it's intended purpose, it's more of used as a massive compression algorithm<br><br>\n",
        "# @markdown The default image used is [ranmewo/voice-changer](https://github.com/Ran-Mewo/voice-changer-docker)<br>You can change it to your own that was created in a [similar way](https://github.com/Ran-Mewo/voice-changer-docker/blob/master/Dockerfile)\n",
        "\n",
        "### This part of the code is by Drengskapur and is licensed under the Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0)\n",
        "### https://github.com/drengskapur/docker-in-colab\n",
        "def udocker_init():\n",
        "    import os\n",
        "    if not os.path.exists(\"/home/user\"):\n",
        "        !pip install udocker > /dev/null\n",
        "        !udocker --allow-root install > /dev/null\n",
        "        !useradd -m user > /dev/null\n",
        "    print(f'Docker-in-Colab 1.1.0\\n')\n",
        "    print(f'Usage:     udocker(\"--help\")')\n",
        "    print(f'Examples:  https://github.com/indigo-dc/udocker?tab=readme-ov-file#examples')\n",
        "\n",
        "    def execute(command: str):\n",
        "        user_prompt = \"\\033[1;32muser@pc\\033[0m\"\n",
        "        print(f\"{user_prompt}$ udocker {command}\")\n",
        "        !su - user -c \"udocker $command\"\n",
        "\n",
        "    return execute\n",
        "\n",
        "udocker = udocker_init()\n",
        "### END OF LICENSED CODE\n",
        "Image = 'ranmewo/voice-changer:latest' # @param {type:\"string\"}\n",
        "\n",
        "!pip install pyngrok\n",
        "!apt-get install -y libportaudio2\n",
        "udocker(f\"--allow-root pull {Image}\")\n",
        "udocker(f\"--allow-root create --name=voice-changer {Image}\")\n",
        "\n",
        "# Set up the python paths so it's linked to the container\n",
        "import sys\n",
        "import os\n",
        "site_packages = \"/home/user/.udocker/containers/voice-changer/ROOT/opt/conda/lib/python3.10/site-packages\"\n",
        "bin = \"/home/user/.udocker/containers/voice-changer/ROOT/opt/conda/bin\"\n",
        "sys.path.append(site_packages)\n",
        "os.environ['PYTHONPATH'] = f\"{site_packages}:{os.environ.get('PYTHONPATH', '')}\"\n",
        "try:\n",
        "    os.remove(f\"{bin}/python\") # Remove the python file so we don't accidentally execute it\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "os.environ['PATH'] = f\"{os.environ['PATH']}:{bin}\""
      ],
      "metadata": {
        "id": "HOEmr0DuyBn2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Link Google Drive (Optional)<br><br><font color=red>⬇(**IMPORTANT**)⬇</font><br>This will create a `voice-changer` folder in your drive, if anything breaks then please try deleting that folder first!\n",
        "drive_path = '/content/drive/MyDrive/voice-changer'\n",
        "system_path = '/home/user/.udocker/containers/voice-changer/ROOT/app'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import os\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "if not os.listdir(drive_path):\n",
        "    # Copy the system_path directory to the drive_path directory\n",
        "    !cp -r {system_path} {drive_path}\n",
        "\n",
        "!rm -rf {system_path}\n",
        "os.symlink(drive_path, system_path, True)\n"
      ],
      "metadata": {
        "id": "x0_acgE9Bvnh",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRluuxSZRngQ"
      },
      "outputs": [],
      "source": [
        "# @title Start Server **using ngrok**\n",
        "# @markdown This cell will start the server, the first time that you run it will download the models, so it can take a while (~1-2 minutes)\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown You'll need a ngrok account, but <font color=green>**it's free**</font> and easy to create!\n",
        "# @markdown ---\n",
        "# @markdown **1** - Create a <font color=green>**free**</font> account at [ngrok](https://dashboard.ngrok.com/signup) or **login with Google/Github account**\\\n",
        "# @markdown **2** - If you didn't logged in with Google/Github, you will need to **verify your e-mail**!\\\n",
        "# @markdown **3** - Click [this link](https://dashboard.ngrok.com/get-started/your-authtoken) to get your auth token, and place it here:\n",
        "Token = '' # @param {type:\"string\"}\n",
        "# @markdown **4** - *(optional)* Change to a region near to you or keep at United States if increase latency\\\n",
        "# @markdown `Default Region: us - United States (Ohio)`\n",
        "Region = \"us - United States (Ohio)\" # @param [\"ap - Asia/Pacific (Singapore)\", \"au - Australia (Sydney)\",\"eu - Europe (Frankfurt)\", \"in - India (Mumbai)\",\"jp - Japan (Tokyo)\",\"sa - South America (Sao Paulo)\", \"us - United States (Ohio)\"]\n",
        "\n",
        "# @markdown **5** - *(optional)* Other options:\n",
        "ClearConsole = True  # @param {type:\"boolean\"}\n",
        "# @markdown **6** - Don't touch unless you know what you're doing!\n",
        "PORT = 8000 # @param {type:\"integer\"}\n",
        "\n",
        "%cd /home/user/.udocker/containers/voice-changer/ROOT/app\n",
        "%cd app\n",
        "%cd server\n",
        "\n",
        "from pyngrok import conf, ngrok\n",
        "MyConfig = conf.PyngrokConfig()\n",
        "MyConfig.auth_token = Token\n",
        "MyConfig.region = Region[0:2]\n",
        "conf.set_default(MyConfig);\n",
        "\n",
        "import subprocess, threading, time, socket, urllib.request\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrokConnection = ngrok.connect(PORT)\n",
        "public_url = ngrokConnection.public_url\n",
        "\n",
        "from IPython.display import clear_output\n",
        "def wait_for_server():\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', PORT))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    if ClearConsole:\n",
        "        clear_output()\n",
        "    print(\"--------- SERVER READY! ---------\")\n",
        "    print(\"Your server is available at:\")\n",
        "    print(public_url)\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "threading.Thread(target=wait_for_server, daemon=True).start()\n",
        "!python MMVCServerSIO.py \\\n",
        "  -p {PORT} \\\n",
        "  --https False \\\n",
        "  --content_vec_500 pretrain/checkpoint_best_legacy_500.pt \\\n",
        "  --content_vec_500_onnx pretrain/content_vec_500.onnx \\\n",
        "  --content_vec_500_onnx_on true \\\n",
        "  --hubert_base pretrain/hubert_base.pt \\\n",
        "  --hubert_base_jp pretrain/rinna_hubert_base_jp.pt \\\n",
        "  --hubert_soft pretrain/hubert/hubert-soft-0d54a1f4.pt \\\n",
        "  --nsf_hifigan pretrain/nsf_hifigan/model \\\n",
        "  --crepe_onnx_full pretrain/crepe_onnx_full.onnx \\\n",
        "  --crepe_onnx_tiny pretrain/crepe_onnx_tiny.onnx \\\n",
        "  --rmvpe pretrain/rmvpe.pt \\\n",
        "  --model_dir model_dir \\\n",
        "  --samples samples.json\n",
        "\n",
        "ngrok.disconnect(ngrokConnection.public_url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyO1rQOYHMzccSPQC/TKuz8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}